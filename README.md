# Multirec

- [Multirec](#multirec)
  - [Описание](#описание)
  - [Статус проекта](#статус-проекта)
  - [Установка](#установка)
    - [Через PyPI](#через-pypi)
    - [Через Kedro](#через-kedro)
  - [Использование](#использование)
    - [Через PyPI](#через-pypi-1)
    - [Через Kedro](#через-kedro-1)
  - [Развертывание](#развертывание)
  - [Доступные модульные пайплайны](#доступные-модульные-пайплайны)
  - [Пайплайны для запуска](#пайплайны-для-запуска)
  - [Кастомные датасеты](#кастомные-датасеты)
  - [Сборка пакета](#сборка-пакета)
  - [Тестирование](#тестирование)
  - [Микроупаковка](#микроупаковка)


## Описание

Multirec представляет собой набор рекомендательных систем для разного рода медиа-развлечений: фильмы, аниме, игры и т.д. 

Данный репозиторий представляет собой набор пайплайнов [Kedro](https://kedro.org/) для построения рекомендаций на основе заданных наборов данных.

## Статус проекта
На текущий момент реализованы рекомендательные системы для следующих медиа-развлечений:
- аниме.

## Установка

### Через PyPI
Установка доступна через `pip`:
```
pip install multirec
```

### Через Kedro

В данном варианте достаточно только клонировать данный репозиторий, затем установить все зависимости с помощью команды `pip install -r src/requirements.txt` и далее работать с CLI Kedro.

## Использование

### Через PyPI
Использование осуществляется с помощью утилиты `multirec` из терминала, устанавливаемой вместе с пакетом (см. [Установка](#через-pypi)). Пример запуска пайплайна, заданного Kedro по умолчанию:
```bash
multirec pipeline
```

Утилиту необходимо запускать внутри директории с каталогами `conf`, `logs` и `data`. Входные данные и параметры пайплайнов задаются в конфигурационных файлах в директории `conf` (см. [Развертывание](#развертывание)). Пути файлов также можно переопределить с помощью флага `--params` (в стандартной утилите Kedro эта функция недоступна):
```bash
kedro manage pipeline --params dataframe:path/to/in.csv,dataframe_with_recs:path/to/out.csv 
```

В данном примере `dataframe` и `dataframe_with_recs` заданы в конфигурационном файле `catalog.yml`, однако в данной команде переопределяются их пути в файловой системе.

### Через Kedro

Для работы с Multirec в данном случае используется стандартная утилита `kedro` ([документация](https://kedro.readthedocs.io/en/stable/development/commands_reference.html)).

**Примечание:** в случае клонирования утилиту Kedro необходимо запускать из корня клонированного репозитория.

## Развертывание

Перед запуском пайплайнов необходимо задать их параметры и входные данные. Для этого необходимо создать нужные для работы директории `conf`, `logs` и `data`. Это можно сделать с помощью команды `multirec deploy`, которая создаст в текущей директории шаблоны конфигурационных файлов, которые необходимо далее заполнить своими значениями.

**Примечание:** развертывание актуально только в случае, если установка производится через PyPI.

## Доступные модульные пайплайны

На данный момент доступны следующие пайплайны:
- [build_recommendations_based_similar](./src/multirec/pipelines/build_recommendations_based_similar/README.md).

Для более наглядного представления входных данных, параметров и выходных данных (откуда берутся, куда записываются и т.д.) пайплайна рекомендуется использовать команду `kedro viz` для визуализации пайплайнов (данная возможность доступна только при клонировании репозитория). Посмотреть описание пайплайнов также можно в коде - в директории `pipelines`.

## Пайплайны для запуска

- `add_recommendations_to_mongo` (на основе [build_recommendations_based_similar](./src/multirec/pipelines/build_recommendations_based_similar/README.md)) - построение рекомендаций для указанного csv и его [импорт](#кастомные-датасеты) в MongoDB;
- `update_recommendations_to_mongo` (на основе [build_recommendations_based_similar](./src/multirec/pipelines/build_recommendations_based_similar/README.md)) - [экспорт](#кастомные-датасеты) указанной коллекции в MongoDB в csv и построение для него рекомендаций, затем импорт обратно в MongoDB с перезаписью.

## Кастомные датасеты

В данном проекте используется кастомный датасет `MongoDBDataset`:
- при загрузке происходит экспорт указанной коллекции в `JSON`, затем его конвертация в `pandas.Dataframe`, который передается далее пайплайну;
- при сохранении происходит конвертация полученного на вход `pandas.Dataframe` в `JSON` и его вставка с перезаписью в указанную коллекцию `MondoDB`.

Пример конфигурации `MongoDBDataset`:
```yml
dataframe_with_recs:
  type: multirec.extras.datasets.mongo_dataset.MongoDBDataset
  filepath: mongodb://localhost:27017
  database: test
  collection: anime
  # filter_columns - опционален
  filter_columns:
    - Name
    - Episodes
    - Studio
    - Rating
    - Description
    - Tags
    - Related_Mange
    - recommendations
```

## Сборка пакета

Для сборки пакета необходимо в корне репозитория выполнить команду `python -m build . --wheel`, после чего в директории `dist` появится пакет `.whl`, который затем можно установить.

## Тестирование

Для тестирования используется tox, содержащий настройки в файле `tox.ini`. Для запуска тестов используется следующая команда:
```bash
tox
``` 

## Микроупаковка

Для микроупаковки пайплайна Kedro необходимо ввести следующую команду:
```bash
kedro micropkg package pipelines.<pipeline_name>
```

Для вставки микропакета пайплайна в другой проект Kedro:
```bash
kedro micropkg pull -d pipelines /path/to/tag.gz
```